### Load necessary packages

import spacy
from collections import Counter
from string import punctuation
from tika import parser

### Set desired number of sentences and keywords

number_sentences = 3
number_keywords = 20

### Load lang pack - choose package size
### en_core_web_lg - c800mb
### en_core_web_md - c100mb 
### en_core_web_sm - c11mb 

nlp = spacy.load("en_core_web_md")

### Parse data from files and get text content

file = 'file'
file_data = parser.from_file(file)
text = file_data['content']

### Key sentence function

def top_sentence(text, limit):
    keyword = []
    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']
    doc = nlp(text.lower())
    for token in doc:
        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):
            continue
        if(token.pos_ in pos_tag):
            keyword.append(token.text)
    
    freq_word = Counter(keyword)
    max_freq = Counter(keyword).most_common(1)[0][1]
    for w in freq_word:
        freq_word[w] = (freq_word[w]/max_freq)
        
    sent_strength={}
    for sent in doc.sents:
        for word in sent:
            if word.text in freq_word.keys():
                if sent in sent_strength.keys():
                    sent_strength[sent]+=freq_word[word.text]
                else:
                    sent_strength[sent]=freq_word[word.text]
    
    summary = []
    
    sorted_x = sorted(sent_strength.items(), key=lambda kv: kv[1], reverse=True)
    
    counter = 0
    for i in range(len(sorted_x)):
        summary.append(str(sorted_x[i][0]).capitalize())

        counter += 1
        if(counter >= limit):
            break
            
    return ' '.join(summary)

### Keywords function

def get_keywords(text):
    result = []
    pos_tag = ['PROPN', 'ADJ', 'NOUN']
    doc = nlp(text.lower()) 
    for token in doc:
        
        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):
            continue
        
        if(token.pos_ in pos_tag):
            result.append(token.text)
                
    return result
    
### Print top n sentences and most common n keywords

print(top_sentence(text, number_sentences))
print(Counter(get_keywords(text)).most_common(number_keywords))
